{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Redes neuronales multicapas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejemplo 1D "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "session = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_size = 25\n",
    "data_1d = np.random.normal(size = data_size)\n",
    "x_input_1d = tf.placeholder(shape=[data_size], dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_layer_1d(input_1d, my_filter):\n",
    "    input_2d = tf.expand_dims(input_1d, 0)\n",
    "    input_3d = tf.expand_dims(input_2d, 0)\n",
    "    input_4d = tf.expand_dims(input_3d, 3)\n",
    "    convolution = tf.nn.conv2d(input_4d, filter = my_filter, strides = [1,1,1,1], padding=\"VALID\")\n",
    "    output = tf.squeeze(convolution)\n",
    "    return(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_filter = tf.Variable(tf.random_normal(shape=[1,5,1,1]))\n",
    "my_conv_output = conv_layer_1d(x_input_1d, my_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def activation(input_1d):\n",
    "    return tf.nn.relu(input_1d)\n",
    "my_activation_output = activation(my_conv_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_pool(input_1d, width):\n",
    "    input_2d = tf.expand_dims(input_1d, 0)\n",
    "    input_3d = tf.expand_dims(input_2d, 0)\n",
    "    input_4d = tf.expand_dims(input_3d, 3)\n",
    "    pooling = tf.nn.max_pool(input_4d, ksize=[1,1,width,1], strides=[1,1,1,1], padding=\"VALID\")\n",
    "    output = tf.squeeze(pooling)\n",
    "    return(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_maxpool_ouput = max_pool(my_activation_output, width=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fully_connected(input_layer, num_output):\n",
    "    weight_shape = tf.squeeze(tf.stack([tf.shape(input_layer), [num_output]]))\n",
    "    weight = tf.random_normal(weight_shape, stddev=0.1)\n",
    "    bias = tf.random_normal(shape=[num_output])\n",
    "    input_layer_2d = tf.expand_dims(input_layer,0)\n",
    "    full_output = tf.add(tf.matmul(input_layer_2d, weight), bias)\n",
    "    full_output_1d = tf.squeeze(full_output)\n",
    "    return(full_output_1d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_full_output = fully_connected(my_maxpool_ouput, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "session.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "feed_dict = {x_input_1d: data_1d}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.11726143,  1.2199282 ,  2.08403659, -0.5641956 , -1.97417837,\n",
       "        0.74121749, -0.06573571,  0.68324515,  0.15140036, -1.47523627,\n",
       "       -1.76683959,  0.29992843, -0.40987229, -2.27857269,  0.85453741,\n",
       "        0.90486784, -0.83307896,  0.86211523, -0.72954449, -2.11379079,\n",
       "        1.17546086, -1.09596305,  1.80804086, -0.27225049,  1.95735632])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[ 0.21220557]],\n",
       "\n",
       "        [[-0.8410326 ]],\n",
       "\n",
       "        [[-0.4553594 ]],\n",
       "\n",
       "        [[ 1.3882189 ]],\n",
       "\n",
       "        [[ 1.3427733 ]]]], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.run(my_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: tamaño 25, Operación: convolución con filtro de tamaño 5 + stride de tamaño 1, Resultado: tamaño 21\n",
      "[-5.171997   -2.9822598   2.7564158   2.0292904   0.13940382 -1.8692768\n",
      " -5.0779386  -1.360606    1.9433976  -2.592258   -2.4562511   3.8472493\n",
      "  1.5777737  -1.6131305   0.01685643 -3.3510168  -1.9256727   1.9192178\n",
      "  1.9940488   1.2062836   2.5982141 ]\n"
     ]
    }
   ],
   "source": [
    "# Operación de convolución\n",
    "print(\"Input: tamaño 25, Operación: convolución con filtro de tamaño 5 + stride de tamaño 1, Resultado: tamaño 21\")\n",
    "print(session.run(my_conv_output, feed_dict=feed_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: tamaño 21, Operación: ReLU al array anterior, Resultado: tamaño 21\n",
      "[0.         0.         2.7564158  2.0292904  0.13940382 0.\n",
      " 0.         0.         1.9433976  0.         0.         3.8472493\n",
      " 1.5777737  0.         0.01685643 0.         0.         1.9192178\n",
      " 1.9940488  1.2062836  2.5982141 ]\n"
     ]
    }
   ],
   "source": [
    "# Función de activación\n",
    "print(\"Input: tamaño 21, Operación: ReLU al array anterior, Resultado: tamaño 21\")\n",
    "print(session.run(my_activation_output, feed_dict=feed_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: tamaño 21, Operación: maxpooling con ventana de tamaño 5 + stride de tamaño 1, Resultado: tamaño 17\n",
      "[2.7564158 2.7564158 2.7564158 2.0292904 1.9433976 1.9433976 1.9433976\n",
      " 3.8472493 3.8472493 3.8472493 3.8472493 3.8472493 1.5777737 1.9192178\n",
      " 1.9940488 1.9940488 2.5982141]\n"
     ]
    }
   ],
   "source": [
    "# Operción de Max Pooling\n",
    "print(\"Input: tamaño 21, Operación: maxpooling con ventana de tamaño 5 + stride de tamaño 1, Resultado: tamaño 17\")\n",
    "print(session.run(my_maxpool_ouput, feed_dict=feed_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: tamaño 17, Operación de conectar totalmente la entrada con 5 valores de salida, Resultado: tamaño 5\n",
      "[-0.36904252  0.5647052  -1.968683   -0.60227275 -0.5455638 ]\n"
     ]
    }
   ],
   "source": [
    "# Capa Totalmente Conectada\n",
    "print(\"Input: tamaño 17, Operación de conectar totalmente la entrada con 5 valores de salida, Resultado: tamaño 5\")\n",
    "print(session.run(my_full_output, feed_dict=feed_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejemplo 2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_size = [10,10]\n",
    "data_2d = np.random.normal(size = data_size)\n",
    "x_input_2d = tf.placeholder(dtype=tf.float32, shape=data_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_layer_2d(input_2d, my_filter):\n",
    "    input_3d = tf.expand_dims(input_2d, 0)\n",
    "    input_4d = tf.expand_dims(input_3d, 3)\n",
    "    convolution = tf.nn.conv2d(input_4d, filter=my_filter, strides = [1,2,2,1], padding=\"VALID\")\n",
    "    output = tf.squeeze(convolution)\n",
    "    return(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_filter = tf.Variable(tf.random_normal(shape=[2,2,1,1]))\n",
    "my_conv_output = conv_layer_2d(x_input_2d, my_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def activation(input_2d):\n",
    "    return(tf.nn.relu(input_2d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_activation_output = activation(my_conv_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_pool(input_2d, width, height):\n",
    "    input_3d = tf.expand_dims(input_2d, 0)\n",
    "    input_4d = tf.expand_dims(input_3d, 3)\n",
    "    pooling = tf.nn.max_pool(input_4d, ksize=[1,height,width,1], strides=[1,1,1,1], padding=\"VALID\")\n",
    "    output = tf.squeeze(pooling)\n",
    "    return(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_maxpool_ouput = max_pool(my_activation_output, width=2, height=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fully_connected(input_layer, num_output):\n",
    "    flat_input = tf.reshape(input_layer, [-1])\n",
    "    weight_shape = tf.squeeze(tf.stack([tf.shape(flat_input), [num_output]]))\n",
    "    weight = tf.random_normal(weight_shape, stddev=0.1)\n",
    "    bias = tf.random_normal(shape=[num_output])\n",
    "    input_layer_2d = tf.expand_dims(flat_input,0)\n",
    "    full_output = tf.add(tf.matmul(input_layer_2d, weight), bias)\n",
    "    full_output_1d = tf.squeeze(full_output)\n",
    "    return(full_output_1d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_full_output = fully_connected(my_maxpool_ouput, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "session.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "feed_dict = {x_input_2d: data_2d}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.00794069e+00,  8.14974415e-01,  3.99545355e-01,\n",
       "        -9.99935947e-01,  1.13843544e+00, -1.58561486e+00,\n",
       "         1.69878991e+00,  1.27893390e+00, -4.94362725e-01,\n",
       "         6.88226682e-01],\n",
       "       [ 9.10593947e-01, -8.34740805e-01,  1.01465504e+00,\n",
       "         8.26075158e-01,  2.68018976e-02, -1.25803966e+00,\n",
       "         2.20600669e+00, -4.71856405e-01,  2.81416120e+00,\n",
       "         6.67204146e-01],\n",
       "       [ 1.17116723e+00,  8.27132156e-01, -5.76934334e-01,\n",
       "         1.52032004e+00,  1.10693142e-01, -5.51934746e-01,\n",
       "        -2.36690741e-01,  2.50897165e-01,  1.67329665e-01,\n",
       "        -4.12898991e-01],\n",
       "       [ 5.70793910e-01,  1.14080357e+00,  1.28673527e+00,\n",
       "        -8.07325421e-02, -3.20146727e-02, -2.00174601e-01,\n",
       "         2.28607480e-01, -1.31197492e+00, -1.46031949e+00,\n",
       "         2.00770654e-01],\n",
       "       [ 2.06144033e+00, -1.84161198e+00, -1.82910346e+00,\n",
       "        -1.87444295e+00,  1.26099042e+00,  4.47116593e-01,\n",
       "        -1.98763105e-01,  1.22677526e+00, -1.04526586e+00,\n",
       "         7.58898977e-02],\n",
       "       [ 7.92016184e-01, -2.03856784e+00, -2.87829309e-03,\n",
       "        -1.41251295e+00,  1.38226185e-01, -1.40372369e+00,\n",
       "         4.95912027e-01,  7.25336671e-01, -1.03769544e+00,\n",
       "         1.05439996e-02],\n",
       "       [ 1.90558195e+00,  9.21248468e-01, -1.10458847e-01,\n",
       "         1.25417505e+00,  1.00063406e+00,  2.83981133e-01,\n",
       "         5.84296560e-01,  1.33514876e+00, -1.76276892e-01,\n",
       "         1.33223100e-01],\n",
       "       [ 2.21494690e-04,  1.18561428e+00,  7.85869986e-01,\n",
       "         1.19647010e+00,  1.03308344e+00,  2.62260359e-01,\n",
       "         2.02464408e+00,  8.11791165e-01, -1.12685900e-01,\n",
       "        -3.45510592e-01],\n",
       "       [-5.79428532e-02, -3.86226349e-02,  1.03254127e+00,\n",
       "         1.28147510e+00, -1.12988202e-01,  2.87105434e-01,\n",
       "        -5.03794263e-01,  4.83921285e-01, -5.88272934e-01,\n",
       "         1.39569961e+00],\n",
       "       [-2.04050221e+00, -5.16329469e-01, -9.89326807e-01,\n",
       "         1.30381945e+00, -8.87251533e-01, -2.15019549e-01,\n",
       "         2.39476638e-01, -3.68689058e-01,  3.53876522e-01,\n",
       "         8.49902005e-01]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[-0.81051064]],\n",
       "\n",
       "        [[-1.3463479 ]]],\n",
       "\n",
       "\n",
       "       [[[ 0.74122626]],\n",
       "\n",
       "        [[-0.68318665]]]], dtype=float32)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.run(my_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: tamaño 10x10, Operación: convolución con filtro de tamaño 2x2 + stride de tamaño 2x2, Resultado: tamaño 5x5\n",
      "[[-1.4794567   1.2101513   2.0914173  -1.1412611   1.104199  ]\n",
      " [-2.4191456  -0.570351    0.7664047   0.9198191  -0.79930776]\n",
      " [ 2.7884169   4.9690366  -0.5625584  -1.6185242  -0.03134565]\n",
      " [-3.594647   -1.8339328  -0.6067862  -1.3250389   0.11603214]\n",
      " [-1.0607617  -4.186264   -0.80572134  0.18619394 -1.7206349 ]]\n"
     ]
    }
   ],
   "source": [
    "# Operación de convolución\n",
    "print(\"Input: tamaño 10x10, Operación: convolución con filtro de tamaño 2x2 + stride de tamaño 2x2, Resultado: tamaño 5x5\")\n",
    "print(session.run(my_conv_output, feed_dict=feed_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: tamaño 5x5, Operación: ReLU al array anterior, Resultado: tamaño 5x5\n",
      "[[0.         1.2101513  2.0914173  0.         1.104199  ]\n",
      " [0.         0.         0.7664047  0.9198191  0.        ]\n",
      " [2.7884169  4.9690366  0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.11603214]\n",
      " [0.         0.         0.         0.18619394 0.        ]]\n"
     ]
    }
   ],
   "source": [
    "# Función de activación\n",
    "print(\"Input: tamaño 5x5, Operación: ReLU al array anterior, Resultado: tamaño 5x5\")\n",
    "print(session.run(my_activation_output, feed_dict=feed_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: tamaño 5x5, Operación: maxpooling con ventana de tamaño 2x2 + stride de tamaño 1, Resultado: tamaño 4x4\n",
      "[[1.2101513  2.0914173  2.0914173  1.104199  ]\n",
      " [4.9690366  4.9690366  0.9198191  0.9198191 ]\n",
      " [4.9690366  4.9690366  0.         0.11603214]\n",
      " [0.         0.         0.18619394 0.18619394]]\n"
     ]
    }
   ],
   "source": [
    "# Operción de Max Pooling\n",
    "print(\"Input: tamaño 5x5, Operación: maxpooling con ventana de tamaño 2x2 + stride de tamaño 1, Resultado: tamaño 4x4\")\n",
    "print(session.run(my_maxpool_ouput, feed_dict=feed_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: tamaño 4x4, Operación de conectar totalmente la entrada con 5 valores de salida, Resultado: tamaño 5\n",
      "[-3.1488183 -0.9166634  0.6182389 -1.320861   0.6795198]\n"
     ]
    }
   ],
   "source": [
    "# Capa Totalmente Conectada\n",
    "print(\"Input: tamaño 4x4, Operación de conectar totalmente la entrada con 5 valores de salida, Resultado: tamaño 5\")\n",
    "print(session.run(my_full_output, feed_dict=feed_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
