{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unit tests con TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 1s 0us/step\n"
     ]
    }
   ],
   "source": [
    "data_dir = \"../../datasets/MNIST_data/\"\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(train_xdata, train_labels), (test_xdata, test_labels) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_xdata = train_xdata / 255.0\n",
    "test_xdata = test_xdata / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "learning_rate = 0.005\n",
    "evaluation_size = 100\n",
    "image_width = train_xdata[0].shape[0]\n",
    "image_height = train_xdata[0].shape[1]\n",
    "target_size = max(train_labels)+1\n",
    "num_channels = 1\n",
    "generations = 100\n",
    "eval_every = 5\n",
    "conv1_features = 25\n",
    "conv2_features = 50\n",
    "max_pool_size1 = 2\n",
    "max_pool_size2 = 2\n",
    "fully_connected_size1 = 100\n",
    "dropout_prob = 0.75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_input_shape = (batch_size, image_width, image_height, num_channels)\n",
    "x_input = tf.placeholder(tf.float32, shape = x_input_shape)\n",
    "y_target = tf.placeholder(tf.int32, shape = (batch_size))\n",
    "\n",
    "eval_input_shape = (evaluation_size, image_width, image_height, num_channels)\n",
    "eval_input = tf.placeholder(tf.float32, shape = eval_input_shape)\n",
    "eval_target = tf.placeholder(tf.int32, shape = (evaluation_size))\n",
    "\n",
    "dropout = tf.placeholder(tf.float32, shape=())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv1_weight = tf.Variable(tf.truncated_normal([4,4,num_channels, conv1_features],\n",
    "                                              stddev=0.1, dtype=tf.float32))\n",
    "conv1_bias = tf.Variable(tf.zeros([conv1_features], dtype = tf.float32))\n",
    "\n",
    "conv2_weight = tf.Variable(tf.truncated_normal([4,4,conv1_features, conv2_features],\n",
    "                                              stddev=0.1, dtype=tf.float32))\n",
    "conv2_bias = tf.Variable(tf.zeros([conv2_features], dtype = tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_width = image_width//(max_pool_size1*max_pool_size2)\n",
    "result_height = image_height//(max_pool_size1*max_pool_size2)\n",
    "full1_input_size = result_width*result_height*conv2_features\n",
    "\n",
    "full1_weight = tf.Variable(tf.truncated_normal([full1_input_size, fully_connected_size1],\n",
    "                                               stddev=0.1, dtype=tf.float32))\n",
    "full1_bias = tf.Variable(tf.truncated_normal([fully_connected_size1], stddev=0.1, dtype=tf.float32))\n",
    "\n",
    "full2_weight = tf.Variable(tf.truncated_normal([fully_connected_size1, target_size],\n",
    "                                               stddev=0.1, dtype=tf.float32))\n",
    "full2_bias = tf.Variable(tf.truncated_normal([target_size], stddev=0.1, dtype=tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_conv_net(input_data):\n",
    "    conv1 = tf.nn.conv2d(input_data, conv1_weight, strides=[1,1,1,1], padding=\"SAME\")\n",
    "    relu1 = tf.nn.relu(tf.nn.bias_add(conv1, conv1_bias))\n",
    "    max_pool1 = tf.nn.max_pool(relu1, ksize = [1,max_pool_size1, max_pool_size1,1],\n",
    "                              strides = [1,max_pool_size1, max_pool_size1, 1], padding = \"SAME\")\n",
    "    \n",
    "    conv2 = tf.nn.conv2d(max_pool1, conv2_weight, strides=[1,1,1,1], padding=\"SAME\")\n",
    "    relu2 = tf.nn.relu(tf.nn.bias_add(conv2, conv2_bias))\n",
    "    max_pool2 = tf.nn.max_pool(relu2, ksize = [1,max_pool_size2, max_pool_size2,1],\n",
    "                              strides = [1,max_pool_size2, max_pool_size2, 1], padding = \"SAME\")\n",
    "    \n",
    "    final_conv_shape = max_pool2.get_shape().as_list()\n",
    "    final_shape = final_conv_shape[1]*final_conv_shape[2]*final_conv_shape[3]\n",
    "    flat_output = tf.reshape(max_pool2, [final_conv_shape[0], final_shape])\n",
    "    \n",
    "    full_connected1 = tf.nn.relu(tf.add(tf.matmul(flat_output, full1_weight), full1_bias))\n",
    "\n",
    "    full_connected2 = tf.add(tf.matmul(full_connected1, full2_weight), full2_bias)\n",
    "\n",
    "    final_model_output = tf.nn.dropout(full_connected2, dropout)\n",
    "    return final_model_output\n",
    "\n",
    "\n",
    "model_output = my_conv_net(x_input)\n",
    "test_model_output = my_conv_net(eval_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits=model_output, labels=y_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = tf.nn.softmax(model_output)\n",
    "test_prediction = tf.nn.softmax(test_model_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(logits, targets):\n",
    "    batch_predictions = np.argmax(logits, axis=1)\n",
    "    num_correct = np.sum(np.equal(batch_predictions, targets))\n",
    "    return 100.0*num_correct/batch_predictions.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_optim = tf.train.MomentumOptimizer(learning_rate, 0.9)\n",
    "train_step = my_optim.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "session.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DropOutTest(tf.test.TestCase):\n",
    "    def dropout_greater_than(self):\n",
    "        with self.test_session():\n",
    "            self.assertGreater(dropout.eval(), 0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AccuracyTest(tf.test.TestCase):\n",
    "    def accuracy_exact_test(self):\n",
    "        with self.test_session():\n",
    "            test_preds = [[0.9, 0.1], [0.01,0.99]]\n",
    "            test_targets = [0,1]\n",
    "            test_acc = get_accuracy(test_preds, test_targets)\n",
    "            self.assertEqual(test_acc.eval(), 100.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShapeTest(tf.test.TestCase):\n",
    "    def output_shape_test(self):\n",
    "        with self.test_session():\n",
    "            numpy_array = np.zeros([batch_size, target_size])\n",
    "            self.assertShapeEqual(numpy_array, model_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(argv):\n",
    "    train_loss = []\n",
    "    train_acc = []\n",
    "    test_acc = []\n",
    "    \n",
    "    for i in range(generations):\n",
    "        rand_idx = np.random.choice(len(train_xdata), size = batch_size)\n",
    "        rand_x = train_xdata[rand_idx]\n",
    "        rand_x = np.expand_dims(rand_x, 3)\n",
    "        rand_y = train_labels[rand_idx]\n",
    "        train_dict = {x_input:rand_x, y_target:rand_y, dropout: dropout_prob}\n",
    "        \n",
    "        session.run(train_step, feed_dict=train_dict)\n",
    "        temp_train_loss, temp_train_preds = session.run([loss, prediction], feed_dict=train_dict)\n",
    "        temp_train_acc = get_accuracy(temp_train_preds, rand_y)\n",
    "        \n",
    "        if (i+1) & eval_every == 0:\n",
    "            eval_idx = np.random.choice(len(test_xdata), size = evaluation_size)\n",
    "            eval_x = test_xdata[eval_idx]\n",
    "            eval_x = np.expand_dims(eval_x, 3)\n",
    "            eval_y = test_labels[eval_idx]\n",
    "            test_dict = {eval_input:eval_x, eval_target:eval_y, dropout: 1.0}\n",
    "            \n",
    "            test_preds = session.run(test_prediction, feed_dict=test_dict)\n",
    "            temp_test_acc = get_accuracy(test_preds, eval_y)\n",
    "            \n",
    "            train_loss.append(temp_train_loss)\n",
    "            train_acc.append(temp_train_acc)\n",
    "            test_acc.append(temp_test_acc)\n",
    "            \n",
    "            acc_and_loss = [(i+1), temp_train_loss, temp_train_acc, temp_test_acc]\n",
    "            acc_and_loss = [np.round(x,2) for x in acc_and_loss]\n",
    "            print(\"Step: {}, Train loss {:.2f}, Train Acc: {:.2f}, Test Acc: {:.2f}\".format(*acc_and_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 2, Train loss 0.48, Train Acc: 79.00, Test Acc: 88.00\n",
      "Step: 8, Train loss 0.50, Train Acc: 77.00, Test Acc: 93.00\n",
      "Step: 10, Train loss 0.56, Train Acc: 79.00, Test Acc: 93.00\n",
      "Step: 16, Train loss 0.43, Train Acc: 80.00, Test Acc: 95.00\n",
      "Step: 18, Train loss 0.44, Train Acc: 82.00, Test Acc: 98.00\n",
      "Step: 24, Train loss 0.36, Train Acc: 83.00, Test Acc: 93.00\n",
      "Step: 26, Train loss 0.52, Train Acc: 77.00, Test Acc: 95.00\n",
      "Step: 32, Train loss 0.53, Train Acc: 78.00, Test Acc: 97.00\n",
      "Step: 34, Train loss 0.46, Train Acc: 77.00, Test Acc: 95.00\n",
      "Step: 40, Train loss 0.53, Train Acc: 81.00, Test Acc: 94.00\n",
      "Step: 42, Train loss 0.40, Train Acc: 87.00, Test Acc: 96.00\n",
      "Step: 48, Train loss 0.38, Train Acc: 84.00, Test Acc: 93.00\n",
      "Step: 50, Train loss 0.34, Train Acc: 86.00, Test Acc: 96.00\n",
      "Step: 56, Train loss 0.51, Train Acc: 78.00, Test Acc: 97.00\n",
      "Step: 58, Train loss 0.40, Train Acc: 81.00, Test Acc: 95.00\n",
      "Step: 64, Train loss 0.51, Train Acc: 80.00, Test Acc: 96.00\n",
      "Step: 66, Train loss 0.52, Train Acc: 76.00, Test Acc: 98.00\n",
      "Step: 72, Train loss 0.55, Train Acc: 75.00, Test Acc: 95.00\n",
      "Step: 74, Train loss 0.45, Train Acc: 80.00, Test Acc: 92.00\n",
      "Step: 80, Train loss 0.60, Train Acc: 73.00, Test Acc: 97.00\n",
      "Step: 82, Train loss 0.51, Train Acc: 82.00, Test Acc: 95.00\n",
      "Step: 88, Train loss 0.46, Train Acc: 83.00, Test Acc: 93.00\n",
      "Step: 90, Train loss 0.43, Train Acc: 78.00, Test Acc: 96.00\n",
      "Step: 96, Train loss 0.52, Train Acc: 76.00, Test Acc: 97.00\n",
      "Step: 98, Train loss 0.54, Train Acc: 75.00, Test Acc: 98.00\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.5/site-packages/IPython/core/interactiveshell.py:2969: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    cmd_args = sys.argv\n",
    "    if len(cmd_args)>1 and cmd_args[1] == \"test\":\n",
    "        tf.test.main(argv=cmd_args[1:])\n",
    "    else:\n",
    "        tf.app.run(main = None, argv=cmd_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
