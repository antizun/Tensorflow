{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.5"
    },
    "colab": {
      "name": "01-unit-tests_colab.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eInfNLeQmIWD",
        "colab_type": "text"
      },
      "source": [
        "# Clonamos el repositorio para obtener los dataSet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P4tnr591mIQn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git clone https://github.com/joanby/tensorflow.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xQ5dAhT9mILP",
        "colab_type": "text"
      },
      "source": [
        "# Damos acceso a nuestro Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7YJbJlXsmIGh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V72FC-l8mIBQ",
        "colab_type": "text"
      },
      "source": [
        "# Test it"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0XY4KeD2mH8W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ls '/content/drive/My Drive' "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9LvOgJXXmH3p",
        "colab_type": "text"
      },
      "source": [
        "# Google colab tools"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LFkV7b2hmHy_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files # Para manejar los archivos y, por ejemplo, exportar a su navegador\n",
        "import glob # Para manejar los archivos y, por ejemplo, exportar a su navegador\n",
        "from google.colab import drive # Montar tu Google drive"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rTVcaT6ZmHtw",
        "colab_type": "text"
      },
      "source": [
        "##Especificando la versión de TensorFlow\n",
        "\n",
        "Ejecutando \"importar tensorflow\" importará la versión por defecto (actualmente 2.x). Puedes usar la 1.x ejecutando una celda con la \"versión mágica de tensorflow\" **antes de ejecutar \"importar tensorflow\".\n",
        "\n",
        "### Si no funciona hacer el pip install\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R5SqimrqmHox",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!pip install tensorflow==1.14\n",
        "%tensorflow_version 1.x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4GgNGgvdmHjA",
        "colab_type": "text"
      },
      "source": [
        "# Importar Tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_o354kx0mHX2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eCS0hH6TmHUF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "session = tf.Session()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CZu0NHOXmFzK",
        "colab_type": "text"
      },
      "source": [
        "# Unit tests con TensorFlow"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yyhRJQ3NmFzL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "import numpy as np\n",
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "irzvNbyQmFzN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "session = tf.Session()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lxL7zcOFmFzQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_dir = \"/content/tensorflow/datasets/MNIST_data\"\n",
        "mnist = tf.keras.datasets.mnist\n",
        "(train_xdata, train_labels), (test_xdata, test_labels) = mnist.load_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LIoNyXyEmFzS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_xdata = train_xdata / 255.0\n",
        "test_xdata = test_xdata / 255.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t6uX0sHAmFzV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 100\n",
        "learning_rate = 0.005\n",
        "evaluation_size = 100\n",
        "image_width = train_xdata[0].shape[0]\n",
        "image_height = train_xdata[0].shape[1]\n",
        "target_size = max(train_labels)+1\n",
        "num_channels = 1\n",
        "generations = 100\n",
        "eval_every = 5\n",
        "conv1_features = 25\n",
        "conv2_features = 50\n",
        "max_pool_size1 = 2\n",
        "max_pool_size2 = 2\n",
        "fully_connected_size1 = 100\n",
        "dropout_prob = 0.75"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eWVHPbTimFzY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_input_shape = (batch_size, image_width, image_height, num_channels)\n",
        "x_input = tf.placeholder(tf.float32, shape = x_input_shape)\n",
        "y_target = tf.placeholder(tf.int32, shape = (batch_size))\n",
        "\n",
        "eval_input_shape = (evaluation_size, image_width, image_height, num_channels)\n",
        "eval_input = tf.placeholder(tf.float32, shape = eval_input_shape)\n",
        "eval_target = tf.placeholder(tf.int32, shape = (evaluation_size))\n",
        "\n",
        "dropout = tf.placeholder(tf.float32, shape=())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OqQEdwZDmFza",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "conv1_weight = tf.Variable(tf.truncated_normal([4,4,num_channels, conv1_features],\n",
        "                                              stddev=0.1, dtype=tf.float32))\n",
        "conv1_bias = tf.Variable(tf.zeros([conv1_features], dtype = tf.float32))\n",
        "\n",
        "conv2_weight = tf.Variable(tf.truncated_normal([4,4,conv1_features, conv2_features],\n",
        "                                              stddev=0.1, dtype=tf.float32))\n",
        "conv2_bias = tf.Variable(tf.zeros([conv2_features], dtype = tf.float32))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gHq4NSoJmFzd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "result_width = image_width//(max_pool_size1*max_pool_size2)\n",
        "result_height = image_height//(max_pool_size1*max_pool_size2)\n",
        "full1_input_size = result_width*result_height*conv2_features\n",
        "\n",
        "full1_weight = tf.Variable(tf.truncated_normal([full1_input_size, fully_connected_size1],\n",
        "                                               stddev=0.1, dtype=tf.float32))\n",
        "full1_bias = tf.Variable(tf.truncated_normal([fully_connected_size1], stddev=0.1, dtype=tf.float32))\n",
        "\n",
        "full2_weight = tf.Variable(tf.truncated_normal([fully_connected_size1, target_size],\n",
        "                                               stddev=0.1, dtype=tf.float32))\n",
        "full2_bias = tf.Variable(tf.truncated_normal([target_size], stddev=0.1, dtype=tf.float32))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "luRj7SfRmFzf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def my_conv_net(input_data):\n",
        "    conv1 = tf.nn.conv2d(input_data, conv1_weight, strides=[1,1,1,1], padding=\"SAME\")\n",
        "    relu1 = tf.nn.relu(tf.nn.bias_add(conv1, conv1_bias))\n",
        "    max_pool1 = tf.nn.max_pool(relu1, ksize = [1,max_pool_size1, max_pool_size1,1],\n",
        "                              strides = [1,max_pool_size1, max_pool_size1, 1], padding = \"SAME\")\n",
        "    \n",
        "    conv2 = tf.nn.conv2d(max_pool1, conv2_weight, strides=[1,1,1,1], padding=\"SAME\")\n",
        "    relu2 = tf.nn.relu(tf.nn.bias_add(conv2, conv2_bias))\n",
        "    max_pool2 = tf.nn.max_pool(relu2, ksize = [1,max_pool_size2, max_pool_size2,1],\n",
        "                              strides = [1,max_pool_size2, max_pool_size2, 1], padding = \"SAME\")\n",
        "    \n",
        "    final_conv_shape = max_pool2.get_shape().as_list()\n",
        "    final_shape = final_conv_shape[1]*final_conv_shape[2]*final_conv_shape[3]\n",
        "    flat_output = tf.reshape(max_pool2, [final_conv_shape[0], final_shape])\n",
        "    \n",
        "    full_connected1 = tf.nn.relu(tf.add(tf.matmul(flat_output, full1_weight), full1_bias))\n",
        "\n",
        "    full_connected2 = tf.add(tf.matmul(full_connected1, full2_weight), full2_bias)\n",
        "\n",
        "    final_model_output = tf.nn.dropout(full_connected2, dropout)\n",
        "    return final_model_output\n",
        "\n",
        "\n",
        "model_output = my_conv_net(x_input)\n",
        "test_model_output = my_conv_net(eval_input)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TJbR5AQEmFzh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits=model_output, labels=y_target))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IVRnxpcMmFzm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "prediction = tf.nn.softmax(model_output)\n",
        "test_prediction = tf.nn.softmax(test_model_output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vAySUdoZmFzo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_accuracy(logits, targets):\n",
        "    batch_predictions = np.argmax(logits, axis=1)\n",
        "    num_correct = np.sum(np.equal(batch_predictions, targets))\n",
        "    return 100.0*num_correct/batch_predictions.shape[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nJ4vvDYNmFzq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "my_optim = tf.train.MomentumOptimizer(learning_rate, 0.9)\n",
        "train_step = my_optim.minimize(loss)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "03xCg_9JmFzs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "init = tf.global_variables_initializer()\n",
        "session.run(init)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0M6nXkTlmFzu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DropOutTest(tf.test.TestCase):\n",
        "    def dropout_greater_than(self):\n",
        "        with self.test_session():\n",
        "            self.assertGreater(dropout.eval(), 0.25)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PuvT_dGzmFzv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class AccuracyTest(tf.test.TestCase):\n",
        "    def accuracy_exact_test(self):\n",
        "        with self.test_session():\n",
        "            test_preds = [[0.9, 0.1], [0.01,0.99]]\n",
        "            test_targets = [0,1]\n",
        "            test_acc = get_accuracy(test_preds, test_targets)\n",
        "            self.assertEqual(test_acc.eval(), 100.0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yNZdD-OGmFzx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ShapeTest(tf.test.TestCase):\n",
        "    def output_shape_test(self):\n",
        "        with self.test_session():\n",
        "            numpy_array = np.zeros([batch_size, target_size])\n",
        "            self.assertShapeEqual(numpy_array, model_output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K2GYnSE0mFzz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def main(argv):\n",
        "    train_loss = []\n",
        "    train_acc = []\n",
        "    test_acc = []\n",
        "    \n",
        "    for i in range(generations):\n",
        "        rand_idx = np.random.choice(len(train_xdata), size = batch_size)\n",
        "        rand_x = train_xdata[rand_idx]\n",
        "        rand_x = np.expand_dims(rand_x, 3)\n",
        "        rand_y = train_labels[rand_idx]\n",
        "        train_dict = {x_input:rand_x, y_target:rand_y, dropout: dropout_prob}\n",
        "        \n",
        "        session.run(train_step, feed_dict=train_dict)\n",
        "        temp_train_loss, temp_train_preds = session.run([loss, prediction], feed_dict=train_dict)\n",
        "        temp_train_acc = get_accuracy(temp_train_preds, rand_y)\n",
        "        \n",
        "        if (i+1) & eval_every == 0:\n",
        "            eval_idx = np.random.choice(len(test_xdata), size = evaluation_size)\n",
        "            eval_x = test_xdata[eval_idx]\n",
        "            eval_x = np.expand_dims(eval_x, 3)\n",
        "            eval_y = test_labels[eval_idx]\n",
        "            test_dict = {eval_input:eval_x, eval_target:eval_y, dropout: 1.0}\n",
        "            \n",
        "            test_preds = session.run(test_prediction, feed_dict=test_dict)\n",
        "            temp_test_acc = get_accuracy(test_preds, eval_y)\n",
        "            \n",
        "            train_loss.append(temp_train_loss)\n",
        "            train_acc.append(temp_train_acc)\n",
        "            test_acc.append(temp_test_acc)\n",
        "            \n",
        "            acc_and_loss = [(i+1), temp_train_loss, temp_train_acc, temp_test_acc]\n",
        "            acc_and_loss = [np.round(x,2) for x in acc_and_loss]\n",
        "            print(\"Step: {}, Train loss {:.2f}, Train Acc: {:.2f}, Test Acc: {:.2f}\".format(*acc_and_loss))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "jzUmtheKmFz1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if __name__ == \"__main__\":\n",
        "    cmd_args = sys.argv\n",
        "    if len(cmd_args)>1 and cmd_args[1] == \"test\":\n",
        "        tf.test.main(argv=cmd_args[1:])\n",
        "    else:\n",
        "        tf.app.run(main = None, argv=cmd_args)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}