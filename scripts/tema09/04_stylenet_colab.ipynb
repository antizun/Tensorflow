{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.5"
    },
    "colab": {
      "name": "04-stylenet_colab.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q1pjQp8BUzh-",
        "colab_type": "text"
      },
      "source": [
        "# Clonamos el repositorio para obtener los dataSet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JHnIDBP-UzcT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "832ca441-562e-4254-8dca-07ac877ceeb0"
      },
      "source": [
        "!git clone https://github.com/joanby/tensorflow.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'tensorflow'...\n",
            "remote: Enumerating objects: 51, done.\u001b[K\n",
            "remote: Counting objects: 100% (51/51), done.\u001b[K\n",
            "remote: Compressing objects: 100% (28/28), done.\u001b[K\n",
            "remote: Total 60311 (delta 32), reused 37 (delta 23), pack-reused 60260\u001b[K\n",
            "Receiving objects: 100% (60311/60311), 442.46 MiB | 34.39 MiB/s, done.\n",
            "Resolving deltas: 100% (82/82), done.\n",
            "Checking out files: 100% (60225/60225), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fkazrc3wUzWg",
        "colab_type": "text"
      },
      "source": [
        "# Damos acceso a nuestro Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F4GLI8o6UzRO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YfcQzDlsUzLQ",
        "colab_type": "text"
      },
      "source": [
        "# Test it"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LhW1frtbUzFg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ls '/content/drive/My Drive' "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mPjj9SVCUy_R",
        "colab_type": "text"
      },
      "source": [
        "# Google colab tools"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aXtDwHc2Uy50",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files # Para manejar los archivos y, por ejemplo, exportar a su navegador\n",
        "import glob # Para manejar los archivos y, por ejemplo, exportar a su navegador\n",
        "from google.colab import drive # Montar tu Google drive"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OJhsnVYZUyz0",
        "colab_type": "text"
      },
      "source": [
        "##Especificando la versión de TensorFlow\n",
        "\n",
        "Ejecutando \"importar tensorflow\" importará la versión por defecto (actualmente 2.x). Puedes usar la 1.x ejecutando una celda con la \"versión mágica de tensorflow\" **antes de ejecutar \"importar tensorflow\".\n",
        "\n",
        "### Si no funciona hacer el pip install\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QM2MRBKBUytq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b8586a70-e60a-473c-975e-208f8af56854"
      },
      "source": [
        "#!pip install tensorflow==1.14\n",
        "%tensorflow_version 1.x"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "alqgHk6WUyk7",
        "colab_type": "text"
      },
      "source": [
        "# Importar Tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KGwxdm1kUyS5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4d353ba9-bcd5-4d5a-d58c-886a24b6b6d3"
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.15.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vEGoguF4UyMs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "session = tf.Session()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mei4s-x4UuQP",
        "colab_type": "text"
      },
      "source": [
        "# Stylenet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mwrulOg_UuQR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import scipy.io\n",
        "import scipy.misc\n",
        "import imageio\n",
        "from skimage.transform import resize\n",
        "from operator import mul\n",
        "from functools import reduce\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.python.framework import ops\n",
        "import urllib.request"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kQFdjqhLUuQV",
        "colab_type": "text"
      },
      "source": [
        "Ficheros de imágenes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z6L0mNhRUuQW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ops.reset_default_graph()\n",
        "original_image_file = \"/content/tensorflow/datasets/stylenet/original_image.jpg\"\n",
        "style_image_file = \"/content/tensorflow/datasets/stylenet/style_image.jpg\""
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Av8_rbCmXKdQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7c7be44a-05ad-4e09-a34d-0073b491763f"
      },
      "source": [
        "model_url = \"http://www.vlfeat.org/matconvnet/models/beta16/imagenet-vgg-verydeep-19.mat\"\n",
        "data_dir = './datasets/model'\n",
        "if not os.path.isdir(data_dir):\n",
        "    os.makedirs(data_dir)\n",
        "\n",
        "target_file = os.path.join(data_dir, 'imagenet-vgg-verydeep-19.mat')\n",
        "if not os.path.isfile(target_file):\n",
        "    print(\"imagenet-vgg-verydeep-19.mat no descargado, vamos a bajarlo (Tamaño estimado =~ 550 Mb)\")\n",
        "    file, headers = urllib.request.urlretrieve(model_url, target_file)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "imagenet-vgg-verydeep-19.mat no descargado, vamos a bajarlo (Tamaño estimado =~ 550 Mb)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E09uYDYXUuQZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vgg_path = \"/content/datasets/model/imagenet-vgg-verydeep-19.mat\"\n",
        "original_image_weight = 5.0\n",
        "style_image_weight = 500.0\n",
        "regularization_weight = 100\n",
        "learning_rate = 10\n",
        "generations = 100\n",
        "output_generations = 10\n",
        "beta1 = 0.9\n",
        "beta2 = 0.999"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QLN-ErPJUuQi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "original_image = imageio.imread(original_image_file)\n",
        "style_image = imageio.imread(style_image_file)"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xT2sHsDiUuQk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "target_shape = original_image.shape\n",
        "style_image = resize(style_image, target_shape)"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cLvU8ucjUuQn",
        "colab_type": "text"
      },
      "source": [
        "Redes neuronales del paper VGG19 disponible en [Arxiv.org](https://arxiv.org/pdf/1508.06576.pdf)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3xqs7bwHUuQn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vgg_layers = ['conv1_1', 'relu1_1',\n",
        "              'conv1_2', 'relu1_2', 'pool1',\n",
        "              'conv2_1', 'relu2_1',\n",
        "              'conv2_2', 'relu2_2', 'pool2',\n",
        "              'conv3_1', 'relu3_1',\n",
        "              'conv3_2', 'relu3_2',\n",
        "              'conv3_3', 'relu3_3',\n",
        "              'conv3_4', 'relu3_4', 'pool3',\n",
        "              'conv4_1', 'relu4_1',\n",
        "              'conv4_2', 'relu4_2',\n",
        "              'conv4_3', 'relu4_3',\n",
        "              'conv4_4', 'relu4_4', 'pool4',\n",
        "              'conv5_1', 'relu5_1',\n",
        "              'conv5_2', 'relu5_2',\n",
        "              'conv5_3', 'relu5_3',\n",
        "              'conv5_4', 'relu5_4']"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "th2ybvouUuQp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def extract_net_info(path_to_mat_file):\n",
        "    vgg_data = scipy.io.loadmat(path_to_mat_file)\n",
        "    normalization_matrix = vgg_data[\"normalization\"][0][0][0]\n",
        "    mat_mean = np.mean(normalization_matrix, axis=(0,1))\n",
        "    network_weights = vgg_data['layers'][0]\n",
        "    return mat_mean, network_weights"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VXonXg86UuQr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def vgg_network(network_weights, init_image):\n",
        "    network = {}\n",
        "    image = init_image\n",
        "\n",
        "    for i, layer in enumerate(vgg_layers):\n",
        "        if layer[0] == 'c': #convolución\n",
        "            weights, bias = network_weights[i][0][0][0][0]\n",
        "            weights = np.transpose(weights, (1, 0, 2, 3))\n",
        "            bias = bias.reshape(-1)\n",
        "            conv_layer = tf.nn.conv2d(image, tf.constant(weights), (1, 1, 1, 1), 'SAME')\n",
        "            image = tf.nn.bias_add(conv_layer, bias)\n",
        "        elif layer[0] == 'r': #relu\n",
        "            image = tf.nn.relu(image)\n",
        "        else:  #max pooling\n",
        "            image = tf.nn.max_pool(image, (1, 2, 2, 1), (1, 2, 2, 1), 'SAME')\n",
        "        network[layer] = image\n",
        "    return network"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "85WOLuVQUuQu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "original_layers = ['relu4_2', 'relu5_2']\n",
        "style_layers = ['relu1_1', 'relu2_1', 'relu3_1', 'relu4_1', 'relu5_1']"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "agRRWR8fUuQw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get network parameters\n",
        "normalization_mean, network_weights = extract_net_info(vgg_path)"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K6eeRgavUuQy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "shape = (1,) + original_image.shape\n",
        "style_shape = (1,) + style_image.shape"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "31dqXBN7UuQ0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "original_features = {}\n",
        "style_features = {}"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JMTVNkn9UuQ2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "cc074361-56fd-4e31-a9ad-fb970f7b0486"
      },
      "source": [
        "style_weights = {l: 1./(len(style_layers)) for l in style_layers}\n",
        "style_weights"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'relu1_1': 0.2,\n",
              " 'relu2_1': 0.2,\n",
              " 'relu3_1': 0.2,\n",
              " 'relu4_1': 0.2,\n",
              " 'relu5_1': 0.2}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AiNcmOHgUuQ4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "g_original = tf.Graph()\n",
        "with g_original.as_default(), tf.Session() as session1:\n",
        "    image = tf.placeholder(\"float\", shape=shape)\n",
        "    vgg_net = vgg_network(network_weights, image)\n",
        "    original_minus_mean = original_image - normalization_mean\n",
        "    original_norm = np.array([original_minus_mean])\n",
        "    for layer in original_layers:\n",
        "        original_features[layer] = vgg_net[layer].eval(feed_dict={image:original_norm})"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m9uxGZ-PUuQ7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "g_style = tf.Graph()\n",
        "with g_style.as_default(), tf.Session() as session2:\n",
        "    image = tf.placeholder(\"float\", shape=style_shape)\n",
        "    vgg_net = vgg_network(network_weights, image)\n",
        "    style_minus_mean = style_image - normalization_mean\n",
        "    style_norm = np.array([style_minus_mean])\n",
        "    for layer in style_layers:\n",
        "        features = vgg_net[layer].eval(feed_dict={image:style_norm})\n",
        "        features = np.reshape(features, (-1, features.shape[3]))\n",
        "        gram = np.matmul(features.T, features)/features.size\n",
        "        style_features[layer] = gram"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z2RXQx3YUuQ9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with tf.Graph().as_default():\n",
        "    \n",
        "    initial = tf.random_normal(shape)*0.256\n",
        "    init_image = tf.Variable(initial)\n",
        "    vgg_net = vgg_network(network_weights, init_image)\n",
        "    \n",
        "    original_layers_w = {\"relu4_2\":0.5, \"relu5_2\":0.5}\n",
        "    original_loss = 0\n",
        "    for layer in original_layers:\n",
        "        temp_original_loss = original_layers_w[layer]*original_image_weight *\\\n",
        "            (2*tf.nn.l2_loss(vgg_net[layer]-original_features[layer]))\n",
        "        original_loss += temp_original_loss/original_features[layer].size\n",
        "    style_loss = 0\n",
        "    style_losses = []\n",
        "    for style_layer in style_layers:\n",
        "        layer = vgg_net[style_layer]\n",
        "        feats, height, width, channels = [x.value for x in layer.get_shape()]\n",
        "        size = height * width * channels\n",
        "        features = tf.reshape(layer, (-1, channels))\n",
        "        style_gram_matrix = tf.matmul(tf.transpose(features), features) / size\n",
        "        style_expected = style_features[style_layer]\n",
        "        style_losses.append(style_weights[style_layer] * 2 *\n",
        "                            tf.nn.l2_loss(style_gram_matrix - style_expected) /\n",
        "                            style_expected.size)\n",
        "    style_loss += style_image_weight * tf.reduce_sum(style_losses)\n",
        "    \n",
        "    total_var_x = reduce(mul, init_image[:,1:,:,:].get_shape().as_list(),1)\n",
        "    total_var_y = reduce(mul, init_image[:,:,1:,:].get_shape().as_list(),1)\n",
        "    \n",
        "    first_term = regularization_weight*2\n",
        "    second_term_num = tf.nn.l2_loss(init_image[:,1:, :,:]- init_image[:,:shape[1]-1,:,:])\n",
        "    second_term = second_term_num/total_var_y\n",
        "    third_term_num = tf.nn.l2_loss(init_image[:,:,1:,:]-init_image[:,:,:shape[2]-1,:])\n",
        "    third_term = third_term_num/total_var_x\n",
        "    total_var_loss = first_term*(second_term+third_term)\n",
        "    \n",
        "    loss = original_loss+style_loss+total_var_loss\n",
        "    \n",
        "    optim = tf.train.AdamOptimizer(learning_rate, beta1, beta2)\n",
        "    train_step = optim.minimize(loss)\n",
        "    \n",
        "    with tf.Session() as session:\n",
        "        tf.global_variables_initializer().run()\n",
        "        for i in range(generations):\n",
        "            train_step.run()\n",
        "            \n",
        "            if (i+1)% output_generations==0:\n",
        "                print(\"Iteración {} de {}, loss {}\".format(i+1, generations, session.run(loss)))\n",
        "                image_eval = init_image.eval()\n",
        "                best_image_add_mean = image_eval.reshape(shape[1:])+normalization_mean\n",
        "                output_file = 'temp_output_{}.jpg'.format(i+1)\n",
        "                imageio.imwrite(output_file, best_image_add_mean.astype(np.uint8))\n",
        "        \n",
        "        image_eval = init_image.eval()\n",
        "        best_image_add_mean = image_eval.reshape(shape[1:])+normalization_mean\n",
        "        output_file = 'final_output.jpg'\n",
        "        imageio.imwrite(output_file, best_image_add_mean.astype(np.uint8))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}