{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.5"
    },
    "colab": {
      "name": "02-advanced-cnn_colab.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7qcXC52WRD65",
        "colab_type": "text"
      },
      "source": [
        "# Clonamos el repositorio para obtener los dataSet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fASbtGCpRD0o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git clone https://github.com/joanby/tensorflow.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bPiLhxHzRDuU",
        "colab_type": "text"
      },
      "source": [
        "# Damos acceso a nuestro Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "am7HUq3fRDog",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MggCfWOqRDh8",
        "colab_type": "text"
      },
      "source": [
        "# Test it"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OGJ8S6yQRDbf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ls '/content/drive/My Drive' "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MHWZpvfCRDUU",
        "colab_type": "text"
      },
      "source": [
        "# Google colab tools"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VP-W4bOSRDNz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files # Para manejar los archivos y, por ejemplo, exportar a su navegador\n",
        "import glob # Para manejar los archivos y, por ejemplo, exportar a su navegador\n",
        "from google.colab import drive # Montar tu Google drive"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mu2rYkFFRDG1",
        "colab_type": "text"
      },
      "source": [
        "##Especificando la versión de TensorFlow\n",
        "\n",
        "Ejecutando \"importar tensorflow\" importará la versión por defecto (actualmente 2.x). Puedes usar la 1.x ejecutando una celda con la \"versión mágica de tensorflow\" **antes de ejecutar \"importar tensorflow\".\n",
        "\n",
        "### Si no funciona hacer el pip install\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6lnTfnvnRC_W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!pip install tensorflow==1.14\n",
        "%tensorflow_version 1.x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IyPYx4BkRC1X",
        "colab_type": "text"
      },
      "source": [
        "# Importar Tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lx7V6QU9RIUo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aYal7ocjRCls",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "session = tf.Session()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C64pkac8RBe1",
        "colab_type": "text"
      },
      "source": [
        "# Una red neuronal convolucional para detectar objetos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y5HzGyMRRBe1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os \n",
        "import sys\n",
        "import tarfile\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from six.moves import urllib\n",
        "session = tf.Session()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3cmHKNsLRBe4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 128\n",
        "output_every = 50\n",
        "generations = 20000\n",
        "eval_every = 500\n",
        "image_height = 32\n",
        "image_width = 32\n",
        "crop_height = 24\n",
        "crop_width = 24\n",
        "num_channels = 3\n",
        "num_targets = 10\n",
        "data_folder = \"cifar-10-batches-bin\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q7WDzznARBe6",
        "colab_type": "text"
      },
      "source": [
        "$$learning\\ rate = 0.1\\cdot 0.9^{\\frac{x}{250}}$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AnDuxaqrRBe7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learning_rate = 0.1\n",
        "lr_decay = 0.9\n",
        "num_gens_to_wait = 250"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sf7mDso1RBe9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image_vect_length = image_height*image_width*num_channels\n",
        "record_length = 1+image_vect_length"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mv9qlowGRBfA",
        "colab_type": "text"
      },
      "source": [
        "### Descarga y procesamiento de CIFAR 10"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wAq84A6URBfA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_dir = '/content/tensorflow/datasets/cifar-10-temp'\n",
        "if not os.path.exists(data_dir):\n",
        "    os.makedirs(data_dir)\n",
        "cifar10_url = \"http://www.cs.toronto.edu/~kriz/cifar-10-binary.tar.gz\"\n",
        "data_file = os.path.join(data_dir, 'cifar-10-binary.tar.gz')\n",
        "if not os.path.isfile(data_file):\n",
        "    filepath, _ = urllib.request.urlretrieve(cifar10_url, data_file)\n",
        "    tarfile.open(filepath, 'r:gz').extractall(data_dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LrlnBNiHRBfD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def read_cifar_files(filename_queue, distort_images = True):\n",
        "    reader = tf.FixedLengthRecordReader(record_bytes=record_length)\n",
        "    key, record_string = reader.read(filename_queue)\n",
        "    #creamos fichero binario\n",
        "    record_bytes = tf.decode_raw(record_string, tf.uint8)\n",
        "    #extraemos la etiqueta\n",
        "    image_label = tf.cast(tf.slice(record_bytes, [0], [1]), tf.int32)\n",
        "    #extraemos la imagen\n",
        "    image_extracted = tf.reshape(tf.slice(record_bytes, [1], [image_vect_length]), [num_channels, image_height, image_width])\n",
        "    #redimensión de imagen\n",
        "    reshaped_image = tf.transpose(image_extracted, [1,2,0])\n",
        "    reshaped_image = tf.cast(reshaped_image, tf.float32)\n",
        "    #crop aleatorio\n",
        "    final_image = tf.image.resize_image_with_crop_or_pad(reshaped_image, crop_width, crop_height)\n",
        "    if distort_images:\n",
        "        #flip aleatorio horizontal, cambiar brillo y contraste\n",
        "        final_image = tf.image.random_flip_left_right(final_image)\n",
        "        final_image = tf.image.random_brightness(final_image, max_delta=63)\n",
        "        final_image = tf.image.random_contrast(final_image, lower=0.2, upper=1.8)\n",
        "    #estandarización por color\n",
        "    final_image = tf.image.per_image_standardization(final_image)\n",
        "    return final_image, image_label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Xr-CJaqRBfF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def input_pipeline(batch_size, train_logical=True):\n",
        "    if train_logical:\n",
        "        files = [os.path.join(data_dir, data_folder, 'data_batch_{}.bin'.format(i)) for i in range(1,6)]\n",
        "    else:\n",
        "        files = [os.path.join(data_dir, data_folder, 'test_batch.bin')]\n",
        "    \n",
        "    filename_queue = tf.train.string_input_producer(files)\n",
        "    image, label = read_cifar_files(filename_queue)\n",
        "    \n",
        "    min_after_dequeue = 1000\n",
        "    capacity = min_after_dequeue+3*batch_size\n",
        "    example_batch, label_batch = tf.train.shuffle_batch([image,label], batch_size, capacity, min_after_dequeue)\n",
        "    return example_batch, label_batch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JumNBBf4RBfH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def cifar_cnn_model(input_images, batch_size, train_logical=True):\n",
        "    def truncated_normal_var(name, shape, dtype):\n",
        "        return tf.get_variable(name=name, shape=shape, dtype=dtype, \n",
        "                               initializer=tf.truncated_normal_initializer(stddev=0.05))\n",
        "    def zero_var(name, shape, dtype):\n",
        "        return tf.get_variable(name=name, shape=shape, dtype=dtype, \n",
        "                              initializer=tf.constant_initializer(0.0))\n",
        "    ## Primera capa de convolución\n",
        "    with tf.variable_scope(\"conv1\") as scope:\n",
        "        ##Conv de 5x5 para 3 canales con un total de 64 nodos al final\n",
        "        conv1_kernel = truncated_normal_var(name=\"conv_lernel1\", shape=[5,5,3,64], dtype=tf.float32)\n",
        "        conv1 = tf.nn.conv2d(input_images, conv1_kernel, [1,1,1,1],padding=\"SAME\")\n",
        "        conv1_bias = zero_var(name=\"conv_bias1\", shape=[64], dtype=tf.float32)\n",
        "        conv1_add_bias = tf.nn.bias_add(conv1, conv1_bias)\n",
        "        ## Capa de relu\n",
        "        relu_conv1 = tf.nn.relu(conv1_add_bias)\n",
        "    #Max pooling\n",
        "    pool1 = tf.nn.max_pool(relu_conv1, ksize=[1,3,3,1], strides=[1,2,2,1],padding=\"SAME\", name=\"pool_layer1\")\n",
        "    \n",
        "    #Normalización local\n",
        "    norm1 = tf.nn.lrn(pool1, depth_radius=5, bias=2.0, alpha=1e-3, beta=0.75, name=\"norm1\")\n",
        "    \n",
        "    ## Segunda capa de convolución\n",
        "    with tf.variable_scope(\"conv2\") as scope:\n",
        "        ##Conv de 5x5 para 64 nodos de entrada con un total de 64 nodos al final\n",
        "        conv2_kernel = truncated_normal_var(name=\"conv_lernel2\", shape=[5,5,64,64], dtype=tf.float32)\n",
        "        conv2 = tf.nn.conv2d(norm1, conv2_kernel, [1,1,1,1],padding=\"SAME\")\n",
        "        conv2_bias = zero_var(name=\"conv_bias2\", shape=[64], dtype=tf.float32)\n",
        "        conv2_add_bias = tf.nn.bias_add(conv2, conv2_bias)\n",
        "        ## Capa de relu\n",
        "        relu_conv2 = tf.nn.relu(conv2_add_bias)\n",
        "    #Max pooling\n",
        "    pool2 = tf.nn.max_pool(relu_conv2, ksize=[1,3,3,1], strides=[1,2,2,1],padding=\"SAME\", name=\"pool_layer2\")\n",
        "    \n",
        "    #Normalización local\n",
        "    norm2 = tf.nn.lrn(pool2, depth_radius=5, bias=2.0, alpha=1e-3, beta=0.75, name=\"norm2\")\n",
        "    \n",
        "    #Redimensionar a una matriz para poder multiplicar en las capas totalmente conectadas\n",
        "    reshaped_output = tf.reshape(norm2, [batch_size,-1])\n",
        "    reshaped_dim = reshaped_output.get_shape()[1].value\n",
        "    \n",
        "    ##Primera capa totalmente conectada\n",
        "    with tf.variable_scope(\"full1\") as scope:\n",
        "        #Full connected con 384 nodos\n",
        "        full_weight1 = truncated_normal_var(name=\"full_mult1\", shape=[reshaped_dim, 384], dtype = tf.float32)\n",
        "        full_bias1 = zero_var(name=\"full_bias1\", shape=[384], dtype=tf.float32)\n",
        "        full_layer1 = tf.nn.relu(tf.add(tf.matmul(reshaped_output, full_weight1), full_bias1))\n",
        "    ##Segunda capa totalmente conectada\n",
        "    with tf.variable_scope(\"full2\") as scope:\n",
        "        #Full connected con 192 nodos\n",
        "        full_weight2 = truncated_normal_var(name=\"full_mult2\", shape=[384, 192], dtype = tf.float32)\n",
        "        full_bias2 = zero_var(name=\"full_bias2\", shape=[192], dtype=tf.float32)\n",
        "        full_layer2 = tf.nn.relu(tf.add(tf.matmul(full_layer1, full_weight2), full_bias2))\n",
        "    ##Tercera capa totalmente conectada\n",
        "    with tf.variable_scope(\"full3\") as scope:\n",
        "        #Full connected con una de las 10 categorías de salida\n",
        "        full_weight3 = truncated_normal_var(name=\"full_mult3\", shape=[192, num_targets], dtype = tf.float32)\n",
        "        full_bias3 = zero_var(name=\"full_bias3\", shape=[num_targets], dtype=tf.float32)\n",
        "        final_output = tf.add(tf.matmul(full_layer2, full_weight3), full_bias3)\n",
        "    \n",
        "    return final_output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rFZES801RBfJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def cifar_loss(logits, targets):\n",
        "    targets = tf.squeeze(tf.cast(targets, tf.int32))\n",
        "    cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits, labels=targets)\n",
        "    cross_entropy_mean = tf.reduce_mean(cross_entropy)\n",
        "    return cross_entropy_mean"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SjXgGsvCRBfL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_step(loss_value, generation_num):\n",
        "    model_learning_rate = tf.train.exponential_decay(learning_rate, generation_num, \n",
        "                                                     num_gens_to_wait, lr_decay, staircase=True)\n",
        "    my_optim = tf.train.GradientDescentOptimizer(model_learning_rate)\n",
        "    train_step = my_optim.minimize(loss_value)\n",
        "    return train_step"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8IxKmp1ERBfN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def accuracy_from_batches(logits, targets):\n",
        "    targets = tf.squeeze(tf.cast(targets, tf.int32))\n",
        "    batch_predictions = tf.cast(tf.argmax(logits,1), tf.int32)\n",
        "    predicted_correctly = tf.equal(batch_predictions, targets)\n",
        "    accuracy = tf.reduce_mean(tf.cast(predicted_correctly, tf.float32))\n",
        "    return accuracy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mJw1jpUTRBfP",
        "colab_type": "text"
      },
      "source": [
        "### Entrenamiento"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kH2mLeiBRBfQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "images, targets = input_pipeline(batch_size, train_logical=True)\n",
        "test_images, test_targets = input_pipeline(batch_size, train_logical=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Ikaqm4rRBfS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with tf.variable_scope('model_definition') as scope:\n",
        "    model_output = cifar_cnn_model(images, batch_size)\n",
        "    scope.reuse_variables()\n",
        "    test_output = cifar_cnn_model(test_images, batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "298NVMfQRBfU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss = cifar_loss(model_output, targets)\n",
        "accuracy = accuracy_from_batches(test_output, test_targets)\n",
        "generation_num = tf.Variable(0, trainable=False)\n",
        "train_op = train_step(loss, generation_num)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2oB7lIADRBfV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "init = tf.global_variables_initializer()\n",
        "session.run(init)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ts-XJd-URBfX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tf.train.start_queue_runners(sess=session)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vkb93PxuRBfa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_loss = []\n",
        "test_acc = []\n",
        "for i in range(generations):\n",
        "    _, loss_value = session.run([train_op, loss])\n",
        "    if (i+1) % output_every == 0:\n",
        "        train_loss.append(loss_value)\n",
        "        print(\"Paso {}, Pérdida: {:.5f}\".format((i+1),loss_value))\n",
        "    if (i+1) % eval_every == 0:\n",
        "        [temp_acc] = session.run([accuracy])\n",
        "        test_acc.append(temp_acc)\n",
        "        print(\"--- Precisión en test: {:.2f}%. ---\".format(100*temp_acc))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TpgH2DFVRBfc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "eval_idx = range(0, generations, eval_every)\n",
        "output_idx = range(0,generations, output_every)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TvjQt6NrRBfe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot(output_idx, train_loss, 'k-')\n",
        "plt.title(\"Softmax Loss para cada iteración\")\n",
        "plt.xlabel(\"Iteración\")\n",
        "plt.ylabel(\"Pérdida en Softmax\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6bVAB8lnRBfg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot(eval_idx, test_acc, 'k-')\n",
        "plt.title(\"Mejora de la precisión en cada iteración\")\n",
        "plt.xlabel(\"Iteración\")\n",
        "plt.ylabel(\"Precisión\")\n",
        "plt.ylim([0,1])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}