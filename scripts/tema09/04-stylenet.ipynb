{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stylenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import scipy.io\n",
    "import scipy.misc\n",
    "import imageio\n",
    "from skimage.transform import resize\n",
    "from operator import mul\n",
    "from functools import reduce\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import ops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ficheros de imágenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "ops.reset_default_graph()\n",
    "original_image_file = \"../../datasets/stylenet/original_image.jpg\"\n",
    "style_image_file = \"../../datasets/stylenet/style_image.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_path = \"../../datasets/stylenet/imagenet-vgg-verydeep-19.mat\"\n",
    "original_image_weight = 5.0\n",
    "style_image_weight = 500.0\n",
    "regularization_weight = 100\n",
    "learning_rate = 10\n",
    "generations = 100\n",
    "output_generations = 10\n",
    "beta1 = 0.9\n",
    "beta2 = 0.999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_image = imageio.imread(original_image_file)\n",
    "style_image = imageio.imread(style_image_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.5/site-packages/skimage/transform/_warps.py:105: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n",
      "/anaconda3/lib/python3.5/site-packages/skimage/transform/_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n"
     ]
    }
   ],
   "source": [
    "target_shape = original_image.shape\n",
    "style_image = resize(style_image, target_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Redes neuronales del paper VGG19 disponible en [Arxiv.org](https://arxiv.org/pdf/1508.06576.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_layers = ['conv1_1', 'relu1_1',\n",
    "              'conv1_2', 'relu1_2', 'pool1',\n",
    "              'conv2_1', 'relu2_1',\n",
    "              'conv2_2', 'relu2_2', 'pool2',\n",
    "              'conv3_1', 'relu3_1',\n",
    "              'conv3_2', 'relu3_2',\n",
    "              'conv3_3', 'relu3_3',\n",
    "              'conv3_4', 'relu3_4', 'pool3',\n",
    "              'conv4_1', 'relu4_1',\n",
    "              'conv4_2', 'relu4_2',\n",
    "              'conv4_3', 'relu4_3',\n",
    "              'conv4_4', 'relu4_4', 'pool4',\n",
    "              'conv5_1', 'relu5_1',\n",
    "              'conv5_2', 'relu5_2',\n",
    "              'conv5_3', 'relu5_3',\n",
    "              'conv5_4', 'relu5_4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_net_info(path_to_mat_file):\n",
    "    vgg_data = scipy.io.loadmat(path_to_mat_file)\n",
    "    normalization_matrix = vgg_data[\"normalization\"][0][0][0]\n",
    "    mat_mean = np.mean(normalization_matrix, axis=(0,1))\n",
    "    network_weights = vgg_data['layers'][0]\n",
    "    return mat_mean, network_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vgg_network(network_weights, init_image):\n",
    "    network = {}\n",
    "    image = init_image\n",
    "\n",
    "    for i, layer in enumerate(vgg_layers):\n",
    "        if layer[0] == 'c': #convolución\n",
    "            weights, bias = network_weights[i][0][0][0][0]\n",
    "            weights = np.transpose(weights, (1, 0, 2, 3))\n",
    "            bias = bias.reshape(-1)\n",
    "            conv_layer = tf.nn.conv2d(image, tf.constant(weights), (1, 1, 1, 1), 'SAME')\n",
    "            image = tf.nn.bias_add(conv_layer, bias)\n",
    "        elif layer[0] == 'r': #relu\n",
    "            image = tf.nn.relu(image)\n",
    "        else:  #max pooling\n",
    "            image = tf.nn.max_pool(image, (1, 2, 2, 1), (1, 2, 2, 1), 'SAME')\n",
    "        network[layer] = image\n",
    "    return network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_layers = ['relu4_2', 'relu5_2']\n",
    "style_layers = ['relu1_1', 'relu2_1', 'relu3_1', 'relu4_1', 'relu5_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get network parameters\n",
    "normalization_mean, network_weights = extract_net_info(vgg_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape = (1,) + original_image.shape\n",
    "style_shape = (1,) + style_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_features = {}\n",
    "style_features = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'relu1_1': 0.2,\n",
       " 'relu2_1': 0.2,\n",
       " 'relu3_1': 0.2,\n",
       " 'relu4_1': 0.2,\n",
       " 'relu5_1': 0.2}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "style_weights = {l: 1./(len(style_layers)) for l in style_layers}\n",
    "style_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_original = tf.Graph()\n",
    "with g_original.as_default(), tf.Session() as session1:\n",
    "    image = tf.placeholder(\"float\", shape=shape)\n",
    "    vgg_net = vgg_network(network_weights, image)\n",
    "    original_minus_mean = original_image - normalization_mean\n",
    "    original_norm = np.array([original_minus_mean])\n",
    "    for layer in original_layers:\n",
    "        original_features[layer] = vgg_net[layer].eval(feed_dict={image:original_norm})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_style = tf.Graph()\n",
    "with g_style.as_default(), tf.Session() as session2:\n",
    "    image = tf.placeholder(\"float\", shape=style_shape)\n",
    "    vgg_net = vgg_network(network_weights, image)\n",
    "    style_minus_mean = style_image - normalization_mean\n",
    "    style_norm = np.array([style_minus_mean])\n",
    "    for layer in style_layers:\n",
    "        features = vgg_net[layer].eval(feed_dict={image:style_norm})\n",
    "        features = np.reshape(features, (-1, features.shape[3]))\n",
    "        gram = np.matmul(features.T, features)/features.size\n",
    "        style_features[layer] = gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteración 10 de 100, loss 13753257.0\n",
      "Iteración 20 de 100, loss 11215834.0\n",
      "Iteración 30 de 100, loss 9811727.0\n",
      "Iteración 40 de 100, loss 8888564.0\n",
      "Iteración 50 de 100, loss 8252655.0\n",
      "Iteración 60 de 100, loss 7791019.0\n",
      "Iteración 70 de 100, loss 7439777.5\n",
      "Iteración 80 de 100, loss 7175545.0\n",
      "Iteración 90 de 100, loss 7359735.0\n",
      "Iteración 100 de 100, loss 7380156.5\n"
     ]
    }
   ],
   "source": [
    "with tf.Graph().as_default():\n",
    "    \n",
    "    initial = tf.random_normal(shape)*0.256\n",
    "    init_image = tf.Variable(initial)\n",
    "    vgg_net = vgg_network(network_weights, init_image)\n",
    "    \n",
    "    original_layers_w = {\"relu4_2\":0.5, \"relu5_2\":0.5}\n",
    "    original_loss = 0\n",
    "    for layer in original_layers:\n",
    "        temp_original_loss = original_layers_w[layer]*original_image_weight *\\\n",
    "            (2*tf.nn.l2_loss(vgg_net[layer]-original_features[layer]))\n",
    "        original_loss += temp_original_loss/original_features[layer].size\n",
    "    style_loss = 0\n",
    "    style_losses = []\n",
    "    for style_layer in style_layers:\n",
    "        layer = vgg_net[style_layer]\n",
    "        feats, height, width, channels = [x.value for x in layer.get_shape()]\n",
    "        size = height * width * channels\n",
    "        features = tf.reshape(layer, (-1, channels))\n",
    "        style_gram_matrix = tf.matmul(tf.transpose(features), features) / size\n",
    "        style_expected = style_features[style_layer]\n",
    "        style_losses.append(style_weights[style_layer] * 2 *\n",
    "                            tf.nn.l2_loss(style_gram_matrix - style_expected) /\n",
    "                            style_expected.size)\n",
    "    style_loss += style_image_weight * tf.reduce_sum(style_losses)\n",
    "    \n",
    "    total_var_x = reduce(mul, init_image[:,1:,:,:].get_shape().as_list(),1)\n",
    "    total_var_y = reduce(mul, init_image[:,:,1:,:].get_shape().as_list(),1)\n",
    "    \n",
    "    first_term = regularization_weight*2\n",
    "    second_term_num = tf.nn.l2_loss(init_image[:,1:, :,:]- init_image[:,:shape[1]-1,:,:])\n",
    "    second_term = second_term_num/total_var_y\n",
    "    third_term_num = tf.nn.l2_loss(init_image[:,:,1:,:]-init_image[:,:,:shape[2]-1,:])\n",
    "    third_term = third_term_num/total_var_x\n",
    "    total_var_loss = first_term*(second_term+third_term)\n",
    "    \n",
    "    loss = original_loss+style_loss+total_var_loss\n",
    "    \n",
    "    optim = tf.train.AdamOptimizer(learning_rate, beta1, beta2)\n",
    "    train_step = optim.minimize(loss)\n",
    "    \n",
    "    with tf.Session() as session:\n",
    "        tf.global_variables_initializer().run()\n",
    "        for i in range(generations):\n",
    "            train_step.run()\n",
    "            \n",
    "            if (i+1)% output_generations==0:\n",
    "                print(\"Iteración {} de {}, loss {}\".format(i+1, generations, session.run(loss)))\n",
    "                image_eval = init_image.eval()\n",
    "                best_image_add_mean = image_eval.reshape(shape[1:])+normalization_mean\n",
    "                output_file = 'temp_output_{}.jpg'.format(i+1)\n",
    "                imageio.imwrite(output_file, best_image_add_mean.astype(np.uint8))\n",
    "        \n",
    "        image_eval = init_image.eval()\n",
    "        best_image_add_mean = image_eval.reshape(shape[1:])+normalization_mean\n",
    "        output_file = 'final_output.jpg'\n",
    "        imageio.imwrite(output_file, best_image_add_mean.astype(np.uint8))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
